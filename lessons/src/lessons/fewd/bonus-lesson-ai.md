class: frontpage

<div>
  <h2>Front-End Web Development</h2>
  <hr/>
  <h1>Leveraging Generative AI</h1>
</div>

---

## Leveraging Generative AI

### Agenda:

- Define Large Language Models (LLMs) and Generative AI
- Summarize how LLMs generate responses
- Identify potential advantages and disadvantages of generative AI tools
- Identify the real-world concerns and implications of generative AI tools

---

## What are Large Language Models (LLMs)?

What comes to mind when you hear Artificial Intelligence?

What are the differences between Artificial Intelligence, Generative AI and Large Language Models?

---

## What are Large Language Models (LLMs)?

| Artificial Intelligence                                                                                                                                                                                               | Generative AI                                                                                                                                                                         | Large Language Models                                                                                                                                  |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| The ability of machines to perform tasks that typically require human-like intelligence, such as learning, problem-solving, pattern recognition, and decision-making, using algorithms, data, and statistical models. | A type of artificial intelligence that is capable of creating new, original content, such as images, music, and text, based on the patterns and styles it has learned from a dataset. | Computer programs or algorithms that are capable of processing and generating natural language text using vast amounts of data and statistical models. |

---

## Training a Machine Learning Model

| Supervised Learning                                                                             | Unsupervised Learning                                                                                             |
| ----------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |
| Supervised learning is a type of machine learning where the model learns from labeled examples. | Unsupervised learning is a type of machine learning where the model learns from unlabeled data.                   |
| It's similar to having a teacher who provides correct answers for the model to learn from.      | It's like exploring a dataset without a teacher, where the model tries to find patterns and structures on its own |

---

## Training a Large Language Model

examples

| Supervised Learning                                                                                                                                                                                                                                                                                       | Unsupervised Learning                                                                                                                                                                                                                                                     |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Fine Tuning                                                                                                                                                                                                                                                                                               | Pre-training                                                                                                                                                                                                                                                              |
| Pre-training is the initial phase where a large language model is exposed to a vast amount of text data. The model learns the structure, patterns, and common language knowledge by assigning values to words and letters. It then uses its knowledge of patterns to predict the next word in a sentence. | The model is trained on a smaller, task-specific dataset. The model adapts its pretrained knowledge to perform well on the target task by adjusting its architecture and parameters. There is typically a human providing guidance to help the model learn at this stage. |

---

## How an LLM Generates Responses:

.row[
.col[

### 1

#### Input

The LLM receives a prompt or input, which is typically a piece of text that provides context or a question that requires a response

]
.col[

### 2

#### Tokenisation

The LLM breaks down the input into individual words, or tokens, which it can then process and analyse

]
.col[

### 3

#### Encoding

Each token is then encoded into a numerical representation that the LLM can understand and manipulate

]
]

---

## How an LLM Generates Responses:

.row[

.col[

### 4

#### Processing

The LLM processes the encoded tokens by analyzing the patterns and relationships between them.

]
.col[

### 5

#### Output

The LLM generates a response by using the patterns and relationships it has learned during training to create new text that is relevant to the input

]
]

---

## LLMs: A Giant Exercise in Statistics

At a very high level, LLMs like ChatGPT generate their responses one word at a time, based on probability.

.row[
.col[

> The promise of large language models is that they

]
.col[

- can `62%`
- will `11%`
- are `7%`
- capture `2%`
- could `2%`
  ]
  ]

However, probability isnâ€™t the only factor - often times lower probability options result in a better output.

<small> Source: [The Economist](https://www.economist.com/interactive/science-and-technology/2023/04/22/large-creative-ai-models-will-transform-how-we-live-and-work)</small>

---

class: frontpage

<div>
  <h2>Front-End Web Development</h2>
  <hr/>
  <h1>HTML tables</h1>
</div>
